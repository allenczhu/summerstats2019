<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Allen Zhu" />

<meta name="date" content="2019-06-16" />

<title>Lecture 2 - Probability and Distributions</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->



<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">stats_2019_lecture_2</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/allenczhu/summerstats2019">
    <span class="fa fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Lecture 2 - Probability and Distributions</h1>
<h4 class="author"><em>Allen Zhu</em></h4>
<h4 class="date"><em>2019-06-16</em></h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2019-06-17
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 2 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>stats_2019_lecture_2/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/jdblischak/workflowr">workflowr</a> (version 1.4.0). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date </a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate" class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git repository, you know the exact version of the code that produced these results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomallenczhusummerstats2019tree5b4f50f6246f1ad31972c1507b74638d2b31d877targetblank5b4f50fa"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/allenczhu/summerstats2019/tree/5b4f50f6246f1ad31972c1507b74638d2b31d877" target="_blank">5b4f50f</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcomallenczhusummerstats2019tree5b4f50f6246f1ad31972c1507b74638d2b31d877targetblank5b4f50fa" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility. The version displayed above was the version of the Git repository at the time these results were generated. <br><br> Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .RData
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the R Markdown and HTML files. If you’ve configured a remote Git repository (see <code>?wflow_git_remote</code>), click on the hyperlinks in the table below to view them.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/allenczhu/summerstats2019/blob/5b4f50f6246f1ad31972c1507b74638d2b31d877/analysis/lecture2.Rmd" target="_blank">5b4f50f</a>
</td>
<td>
Allen Zhu
</td>
<td>
2019-06-17
</td>
<td>
finished draft 1
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/allenczhu/summerstats2019/7c76f6ff961e333054ec6ec09c4018c8d0ac5d7b/docs/lecture2.html" target="_blank">7c76f6f</a>
</td>
<td>
Allen Zhu
</td>
<td>
2019-06-17
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/allenczhu/summerstats2019/1252a7bed27ab76dc6fbbf8eb21165f47820244e/docs/lecture2.html" target="_blank">1252a7b</a>
</td>
<td>
Allen Zhu
</td>
<td>
2019-06-17
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/allenczhu/summerstats2019/blob/a4f57a0772a3477a5929acaf58602c73639ea3c6/analysis/lecture2.Rmd" target="_blank">a4f57a0</a>
</td>
<td>
Allen Zhu
</td>
<td>
2019-06-17
</td>
<td>
Start my new project
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/allenczhu/summerstats2019/72d2ae3b8e76d51417ca05dcf28afef6b1529522/docs/lecture2.html" target="_blank">72d2ae3</a>
</td>
<td>
Allen Zhu
</td>
<td>
2019-06-16
</td>
<td>
Host with GitHub.
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/allenczhu/summerstats2019/6b5724d37838572402ddede4f7bc15fa4e69701a/docs/lecture2.html" target="_blank">6b5724d</a>
</td>
<td>
Allen Zhu
</td>
<td>
2019-06-16
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/allenczhu/summerstats2019/blob/b6473b872aa14b1106931491aaeabbc66d8f4867/analysis/lecture2.Rmd" target="_blank">b6473b8</a>
</td>
<td>
Allen Zhu
</td>
<td>
2019-06-16
</td>
<td>
updated lecture 2
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/allenczhu/summerstats2019/544384306a5a83f3a032bc4822bba84ee90715a4/docs/lecture2.html" target="_blank">5443843</a>
</td>
<td>
Allen Zhu
</td>
<td>
2019-06-16
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/allenczhu/summerstats2019/blob/caf3b56dc9928aee447aee7cac729cefa7d4958c/analysis/lecture2.Rmd" target="_blank">caf3b56</a>
</td>
<td>
Allen Zhu
</td>
<td>
2019-06-16
</td>
<td>
adding lecture 2
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<div id="probability-theory" class="section level2">
<h2>Probability Theory</h2>
<div id="definitions-and-introductions" class="section level3">
<h3>Definitions and Introductions</h3>
<p>An ensemble is a set of of probabilities describing a particular random process. An ensemble is defined by:</p>
<ul>
<li><span class="math inline">\(x\)</span>, the value of a random variable</li>
<li><span class="math inline">\(A_x=\{a_1, a_2, a_3, ..., a_i\}\)</span></li>
<li><span class="math inline">\(P_x=\{p_1, p_2, p_3, ..., p_i\}\)</span></li>
</ul>
<p><span class="math inline">\(A_x\)</span> is the sample space. The sample space of an experiment is the set of all possible outcomes of that experiment.</p>
<p>A random variable (RV) describes an event that we have not yet observed, e.g.:</p>
<ul>
<li>the number of heads in 6 flips of a fair coin,</li>
<li>the number of spam e-mails we will receive today,</li>
<li>whether it rains today.</li>
</ul>
<p>An <em>experiment</em> is a situation involving chance or probability that leads to results called outcomes. <em>Probability</em> is the measure of how likely an event is. An <em>outcome</em> is the result of a single trial of an experiment. An <em>event</em> is one or more outcomes of an experiment.</p>
<p>For example: if your experiment is to roll a fair, 6-sided die, then the possible outcomes are landing on 1, 2, 3, 4, 5, or 6. One event of this experiment is rolling a 5. The probability of rolling a 5 is one sixth.</p>
<p>Rolling a 7 is an example of an impossible event. Therefore, the probability is zero. Rolling a number less than 7 is certain to occur. This is an example of a certain event. The probability of a certain event is 1.</p>
<p>All probabilities have to be be positive and add up to 1. The sum of the probabilities of the distinct outcomes within a sample space is 1.</p>
<p><span class="math inline">\(P(x=a_i) = p_i\)</span>, where <span class="math inline">\(p_i≥0\)</span>.</p>
<p><span class="math display">\[
\sum_{a_i \in A_x} p(x=a_i) = 1
\]</span></p>
<p>Example: probability of finding a certain nucleotide (A, T, C, or G) in the human genome. <span class="math display">\[
p_A = 0.28 \\
p_T = 0.28 \\
p_C = 0.22 \\
p_G = 0.22 \\
\]</span></p>
</div>
<div id="complement-of-an-event" class="section level3">
<h3>Complement of an Event</h3>
<p>The complement of an event <span class="math inline">\(x\)</span> is the set of all outcomes in the sample space that are not included in the outcomes of event <span class="math inline">\(x\)</span>. The complement of event <span class="math inline">\(x\)</span> is represented by <span class="math inline">\(\bar{x}\)</span>. As a probability, <span class="math inline">\(\bar{P}(x)\)</span> is also used.</p>
<p>Given the probability of an event, the probability of its complement can be found by subtracting the given probability from 1. <span class="math display">\[
P(\bar{x}) = 1-P(x)
\]</span></p>
</div>
<div id="mutually-exclusive-events" class="section level3">
<h3>Mutually Exclusive Events</h3>
<p>Two events are mutually exclusive if they cannot occur at the same time (i.e., they have no outcomes in common).</p>
<p>Example: A single 6-sided die is rolled. What is the probability of rolling an odd number or an even number?</p>
<div id="addition-rules" class="section level4">
<h4>Addition Rules</h4>
<p>Addition Rule 1: When two events, <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, are mutually exclusive, the probability that <span class="math inline">\(x\)</span> or <span class="math inline">\(y\)</span> will occur is the sum of the probability of each event.</p>
<p><span class="math inline">\(P(x\ or\ y) = P(x \cup y) = P(x) + P(y)\)</span></p>
<p>Additional Rule 2: When two events, A and B, are non-mutually exclusive, the probability that A or B will occur is:</p>
<p><span class="math display">\[
\begin{align}
P(x\ or\ y) = P(x \cup y) &amp;= P(x) + P(y) - P(x\ and\ y) \\&amp;= P(x) + P(y) - P(x \cap y)
\end{align}
\]</span></p>
</div>
</div>
<div id="independent-and-dependent-events" class="section level3">
<h3>Independent and Dependent Events</h3>
<p>Two events, <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, are independent if the fact that <span class="math inline">\(x\)</span> occurs does not affect the probability of <span class="math inline">\(y\)</span> occurring.</p>
<p>Two events are dependent if the outcome or occurrence of the first affects the outcome or occurrence of the second so that the probability is changed.</p>
</div>
<div id="joint-probabilities" class="section level3">
<h3>Joint Probabilities</h3>
<ul>
<li>Joint Probability: <span class="math inline">\(P(x, y)\)</span></li>
</ul>
<p>If <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are independent, then <span class="math inline">\(P(x,y) = P(x) P(y)\)</span></p>
<ul>
<li>Marginal Probability: <span class="math display">\[
P(x) = \sum_{y} P(x,y)
\]</span></li>
</ul>
<p>A table of single-strand frequencies of human genes:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th></th>
<th>2nd</th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>A</td>
<td>C</td>
<td>G</td>
<td>T</td>
<td>Sum</td>
</tr>
<tr class="even">
<td>1st</td>
<td>A</td>
<td>0.069</td>
<td>0.057</td>
<td>0.077</td>
<td>0.05</td>
<td>0.25</td>
</tr>
<tr class="odd">
<td></td>
<td>C</td>
<td>0.078</td>
<td>0.077</td>
<td>0.035</td>
<td>0.071</td>
<td>0.26</td>
</tr>
<tr class="even">
<td></td>
<td>G</td>
<td>0.078</td>
<td>0.070</td>
<td>0.075</td>
<td>0.047</td>
<td>0.27</td>
</tr>
<tr class="odd">
<td></td>
<td>T</td>
<td>0.029</td>
<td>0.058</td>
<td>0.081</td>
<td>0.048</td>
<td>0.21</td>
</tr>
<tr class="even">
<td></td>
<td>Sum</td>
<td>0.25</td>
<td>0.26</td>
<td>0.27</td>
<td>0.21</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div id="conditional-probability" class="section level3">
<h3>Conditional Probability</h3>
<p>The conditional probability of an event <span class="math inline">\(y\)</span> in relationship to an event <span class="math inline">\(x\)</span> is the probability that event <span class="math inline">\(y\)</span> occurs given that event <span class="math inline">\(x\)</span> has already occurred. The notation for conditional probability is <span class="math inline">\(P(y|x)\)</span> [pronounced as The probability of event <span class="math inline">\(y\)</span> given <span class="math inline">\(x\)</span>].</p>
<p>The probability of <span class="math inline">\(x\)</span> given <span class="math inline">\(y\)</span> is calculated as:</p>
<p><span class="math display">\[
P(x|y) = \frac{P(x,y)}{P(y)}
\]</span></p>
</div>
<div id="probability-rules" class="section level3">
<h3>Probability Rules</h3>
<ul>
<li><p>Product Rule (Chain Rule): <span class="math display">\[
P(x,y) = P(x|y)P(y)
\]</span></p></li>
<li><p>Sum Rule <span class="math display">\[
\begin{aligned}
P(x) &amp;= \sum_{y} P(x,y) \\
&amp;=\sum_{y} P(x|y)P(y)
\end{aligned}
\]</span></p></li>
<li><p>Bayes’ Theorem</p></li>
</ul>
<p>Bayes’ Theorem tells you how ot switch the order of variables in a conditional probability (how to convert <span class="math inline">\(P(x|y)\)</span> into <span class="math inline">\(P(y|x))\)</span>.</p>
<p><span class="math display">\[
P(y|x) = \frac{P(x|y)P(y)}{P(x)}
\]</span></p>
<p><span class="math display">\[
P(y|x) = \frac{P(x|y)P(y)}{\sum_{y}P(x|y)P(y)}
\]</span></p>
</div>
<div id="exercise" class="section level3">
<h3>Exercise</h3>
<p>A rare disease that affects 0.1% of the population. You take a test, which is marketed to be 99% correct, i.e., in 99/100 cases test shows positive when user actually has disease, and in 99/100 cases test shows negative when user actually does not have disease.</p>
<p>The test gives you a positive result. What is the probability that you have the disease given the test result?</p>
<div id="solution" class="section level4">
<h4>Solution</h4>
<p>Write down all the probabilities:</p>
<ul>
<li><span class="math inline">\(P(disease) = 0.001\)</span></li>
<li><span class="math inline">\(P(test\ positive|disease) = 0.99\)</span></li>
<li><span class="math inline">\(P(test\ negative|no\ disease) = 0.99\)</span></li>
</ul>
<p>We want to find <span class="math inline">\(P(disease|test\ positive)\)</span>.</p>
<p>We can use Bayes’ rule.</p>
<p><span class="math display">\[
P(disease|test\ positive) = \frac{P(test\ positive|disease)P(disease)}
{P(test\ positive)}
\]</span></p>
<p>Use the sum rule to obtain <span class="math inline">\(P(test\ positive)\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
P(test\ positive) &amp;=P(test\ positive|disease)P(disease)\\ 
&amp;+P(test\ positive|no\ disease)P(no\ disease)\\
&amp;=(0.99 × 0.001) + (0.01 × 0.999)
=0.01098
\end{aligned}
\]</span></p>
<p>Plug this into Bayes’ theorem.</p>
<p><span class="math display">\[
\begin{aligned}
P(disease|test\ positive) = \frac{0.99 × 0.001}
{0.01098}
=0.09
\end{aligned}
\]</span></p>
<p>Therefore the actual probability of you having the disease given the test result is only 9%, so it is unlikely you are diseased.</p>
</div>
</div>
</div>
<div id="random-variables" class="section level2">
<h2>Random Variables</h2>
<div id="discrete-random-variables" class="section level4">
<h4>Discrete Random Variables</h4>
<p>A <strong>binary random variable</strong> is a RV that can take on only two values, e.g., <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>. Suppose <span class="math inline">\(A\)</span> is a binary RV. We may then write <span class="math inline">\(A \in \lbrace 0, 1 \rbrace\)</span>, meaning that <span class="math inline">\(A\)</span> can take on the values 0 or 1.</p>
<p>A simple example of a situation involving a a binary random variable is the flipping of a fair coin one time. Will the outcome of the flip be heads (1) or tails (0)? If we let <span class="math inline">\(A\)</span> denote the unknown outcome of the flip, then <span class="math inline">\(A\)</span> is a binary random variable.</p>
<p><strong>Discrete random variables</strong> have a discrete sample space, meaning that they can take on only a finite number of values. Suppose <span class="math inline">\(\chi = \lbrace 1, 2, 3,4 \rbrace\)</span> is our sample space, and <span class="math inline">\(X\)</span> is a random variable that takes values in this sample space, ie <span class="math inline">\(X \in \chi\)</span>. Consider, for instance, reaching into a bag with 4 balls, with labels 1, 2, 3 and 4. What is the label on the ball that you select?</p>
<p><span class="math inline">\(0 \leq \Pr(X) \leq 1\)</span>. If <span class="math inline">\(\Pr(X=i)=0\)</span>, you never draw ball <span class="math inline">\(i\)</span>. Alternatively, if <span class="math inline">\(\Pr(X=i)= 1\)</span>, you always draw ball <span class="math inline">\(i\)</span>. In all other cases, (<span class="math inline">\(0 &lt; \Pr(X=i) &lt; 1\)</span>), you sometimes draw ball <span class="math inline">\(i\)</span>. Additionally, the ball that you draw must have either a 1, 2, 3 or 4 on it, so <span class="math display">\[
\begin{align*}
\Pr(X=1) + \Pr(X=2) + \Pr(X=3) + \Pr(X=4) &amp; = 1
\end{align*}
\]</span> More generally, <span class="math inline">\(\sum_{x \in \chi} \Pr(X=x) =1\)</span>.</p>
<p>A discrete random variable <span class="math inline">\(X\)</span> takes on values <span class="math inline">\(x_i\)</span> with probability <span class="math inline">\(p_i\)</span>, <span class="math inline">\(i=1, \ldots, n\)</span>, where <span class="math inline">\(\sum_{i=1}^{n} p_i = 1\)</span>.</p>
</div>
<div id="continuous-random-variables" class="section level4">
<h4>Continuous Random Variables</h4>
<p>In the discrete case, a random variable <span class="math inline">\(X\)</span> could take on only finitely many values. In the continuous case, the random variable may take on infinitely many values. Let’s begin with an example, a Uniform Random Variable.</p>
<p>For continuous random variables the function <span class="math inline">\(p(\cdot)\)</span> is called a <strong>probability density function (PDF)</strong>.</p>
<p>If a random variable <span class="math inline">\(X\)</span> can take on any of a continuum of values, say, any value between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>, then we cannot define it by listing values <span class="math inline">\(x_i\)</span> and giving the probability <span class="math inline">\(p_i\)</span> that <span class="math inline">\(X= x_i\)</span>; for any single value <span class="math inline">\(x_i\)</span>, <span class="math inline">\(\mbox{Prob}(X = x_i )\)</span> is zero! Instead we can define the <em>cumulative distribution function</em>: <span class="math display">\[
F(x) \equiv \mbox{Prob}(X &lt; x ) ,
\]</span> or the <em>probability density function} (pdf)</em>: <span class="math display">\[
\rho (x)\,dx \equiv \mbox{Prob}( X \in [ x, x+\,dx ] ) = F(x+\,dx ) - F(x) .
\]</span> Letting <span class="math inline">\(dx \rightarrow 0\)</span>, we find <span class="math display">\[
\rho (x) = F&#39; (x) ,~~~F(x) = \int_{- \infty}^{x} \rho (t)\,dt .
\]</span> (For a more formal mathematical derivation, find a textbook on probability or measure theory. This will suffice for our purposes.)</p>
</div>
<div id="expected-value-and-variance" class="section level3">
<h3>Expected Value and Variance</h3>
<div id="discrete-random-variables-1" class="section level4">
<h4>Discrete Random Variables</h4>
<p>The <strong>expected value</strong> of a discrete random variable <span class="math inline">\(X\)</span> is defined as</p>
<p><span class="math display">\[
E(X) \equiv \langle X \rangle = \sum_{i=1}^m p_i x_i .
\]</span> This is also sometimes called the mean of the random variable <span class="math inline">\(X\)</span> and denoted as <span class="math inline">\(\mu\)</span>.</p>
<p>Example 1: Roll a fair die and let <span class="math inline">\(X\)</span> be the value that appears. Then <span class="math inline">\(X\)</span> takes on the values <span class="math inline">\(1\)</span> through <span class="math inline">\(6\)</span>, each with probability <span class="math inline">\(1/6\)</span>.</p>
<p><span class="math display">\[
E(X) = \frac{1}{6} \cdot 1 + \frac{1}{6} \cdot 2 + \frac{1}{6} \cdot 3 +
       \frac{1}{6} \cdot 4 + \frac{1}{6} \cdot 5 + \frac{1}{6} \cdot 6 =
\frac{7}{2} .
\]</span></p>
<p>If <span class="math inline">\(X\)</span> is a discrete random variable and <span class="math inline">\(g\)</span> is any function, then <span class="math inline">\(g(X)\)</span> is a discrete random variable and</p>
<p><span class="math display">\[
E(g(X)) = \sum_{i=1}^{m} p_i g( x_i ) .
\]</span></p>
<p>Example: <span class="math inline">\(g(X) = a X + b\)</span>, <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> constants. <span class="math display">\[\begin{eqnarray*}
E(g(X)) &amp; = &amp; \sum_{i=1}^{m} p_i ( a x_i + b ) \\
        &amp; = &amp; a \sum_{i=1}^{m} p_i x_i ~+~ b~~~
              \mbox{(since } \sum_{i=1}^{m} p_i = 1 ) \\
        &amp; = &amp; a \cdot E(X) + b .
\end{eqnarray*}\]</span></p>
<p>Example: <span class="math inline">\(g(X) = X^2\)</span>. Then <span class="math inline">\(E(g(X)) = \sum_{i=1}^{m} p_i x_i^2\)</span>.</p>
<p>In Example 1 above, <span class="math display">\[
E( X^2 ) = \frac{1}{6} \cdot 1^2 + \frac{1}{6} \cdot 2^2 +
           \frac{1}{6} \cdot 3^2 + \frac{1}{6} \cdot 4^2 +
           \frac{1}{6} \cdot 5^2 + \frac{1}{6} \cdot 6^2 = \frac{91}{6} .
\]</span></p>
<p>Let <span class="math inline">\(\mu = E(X)\)</span> denote the expected value of <span class="math inline">\(X\)</span>. The expected value of the <em>square of the difference</em> between <span class="math inline">\(X\)</span> and <span class="math inline">\(\mu\)</span> is</p>
<p><span class="math display">\[\begin{eqnarray*}
E( ( X - \mu )^2 ) &amp; = &amp; \sum_{i=1}^{m} p_i ( x_i - \mu )^2 \\
                   &amp; = &amp; \sum_{i=1}^{m} p_i ( x_i^2 - 2 \mu x_i + \mu^2 ) \\
                   &amp; = &amp; \sum_{i=1}^{m} p_i x_i^2 - 2 \mu \sum_{i=1}^{m} 
                         p_i x_i + \mu^2 \\
                   &amp; = &amp; E( X^2 ) - \mu^2 \\
                   &amp; = &amp; E( X^2 ) - (E(X) )^2 .
\end{eqnarray*}\]</span> The quantity <span class="math inline">\(E( X^2 ) - ( E(X) )^2\)</span> is called the <strong>variance</strong> of the random variable <span class="math inline">\(X\)</span> and is denoted var(<span class="math inline">\(X\)</span>). The square root of the variance, <span class="math inline">\(\sigma \equiv \sqrt{ \mbox{var}(X)}\)</span> is called the <strong>standard deviation</strong>. In Example 1 above, <span class="math display">\[
\mbox{var}(X) = \frac{91}{6} - \left( \frac{7}{2} \right)^2 = \frac{35}{12} .
\]</span></p>
<p>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be two random variables and let <span class="math inline">\(c_1\)</span> and <span class="math inline">\(c_2\)</span> be constants. Then</p>
<p><span class="math display">\[\begin{eqnarray*}
\mbox{var}( c_1 X + c_2 Y ) &amp; = &amp; E( ( c_1 X + c_2 Y )^2 ) ~-~ 
                                  ( E( c_1 X + c_2 Y ) )^2 \\
                            &amp; = &amp; E( c_1^2 X^2 + 2 c_1 c_2 XY + c_2^2 Y^2 ) ~-~
                                  ( c_1 E(X) + c_2 E(Y) )^2 \\
                            &amp; = &amp; c_1^2 E( X^2 ) + 2 c_1 c_2 E(XY) + 
                                  c_2^2 E( Y^2 ) ~- \\
                            &amp;   &amp; [ c_1^2 ( E(X) )^2 +
                                  2 c_1 c_2 E(X) E(Y) + c_2^2 ( E(Y) )^2 ] \\
                            &amp; = &amp; c_1^2 \mbox{var}(X) + c_2^2 \mbox{var}(Y) +
                                  2 c_1 c_2 ( E(XY) - E(X)E(Y) ) .
\end{eqnarray*}\]</span> The <strong>covariance</strong> of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, denoted cov(<span class="math inline">\(X,Y\)</span>), is the quantity <span class="math inline">\(E(XY) - E(X)E(Y)\)</span>.</p>
<p>Two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are said to be <strong>independent</strong> if the value of one does not depend on that of the other; that is, if the probability that <span class="math inline">\(X = x_i\)</span> is the same regardless of the value of <span class="math inline">\(Y\)</span> and the probability that <span class="math inline">\(Y = y_j\)</span> is the same regardless of the value of <span class="math inline">\(X\)</span>. Equivalently, the probability that <span class="math inline">\(X = x_i\)</span> and <span class="math inline">\(Y = y_j\)</span> is the product of the probability that <span class="math inline">\(X = x_i\)</span> and the probability that <span class="math inline">\(Y = y_j\)</span>.</p>
<p>Useful facts about variance:</p>
<p><span class="math inline">\(Var(cX) = c^2Var(x)\)</span> if <span class="math inline">\(c\)</span> is a constant.</p>
<p><span class="math inline">\(Var(X+Y) = Var(X) + Var(Y)\)</span> only if <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent.</p>
<p>Example: Toss two fair coins. There are four equally probable outcomes: HH, HT, TH, TT. Let <span class="math inline">\(X\)</span> equal <span class="math inline">\(1\)</span> if first coin is heads, <span class="math inline">\(0\)</span> if first coin is tails. Let <span class="math inline">\(Y\)</span> equal <span class="math inline">\(1\)</span> if second coin is heads, <span class="math inline">\(0\)</span> if second coin is tails. Then <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent because, for example, <span class="math display">\[
\mbox{Prob}( X=1 \mbox{ and } Y=0 ) = \frac{1}{4} = 
\frac{1}{2} \cdot \frac{1}{2} = \mbox{Prob}( X=1 ) \cdot \mbox{Prob}( Y=0 ) ,
\]</span></p>
<p>and similarly, for all other possible values, <span class="math inline">\(\mbox{Prob}( X= x_i \mbox{ and } Y= y_j ) = \mbox{Prob}( X= x_i ) \cdot \mbox{Prob}( Y= y_j )\)</span>. In contrast, if we define <span class="math inline">\(Y\)</span> to be <span class="math inline">\(0\)</span> if outcome is <span class="math inline">\(TT\)</span> and <span class="math inline">\(1\)</span> otherwise, then <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are not independent because <span class="math inline">\(\mbox{Prob}(X=1 \mbox{ and }Y=0) = 0\)</span>, yet <span class="math inline">\(\mbox{Prob}(X=1) = 1/2\)</span> and <span class="math inline">\(\mbox{Prob}(Y=0) = 1/4\)</span>.</p>
</div>
<div id="continuous-random-variables-1" class="section level4">
<h4>Continuous Random Variables</h4>
<p>The expected value of a continuous random variable <span class="math inline">\(X\)</span> is then defined by <span class="math display">\[
E(X) = \int_{- \infty}^{\infty} x \rho (x)\,dx .
\]</span> Note that by definition, <span class="math inline">\(\int_{- \infty}^{\infty} \rho (x)\,dx = 1\)</span>. The expected value of <span class="math inline">\(X^2\)</span> is <span class="math display">\[
E( X^2 ) = \int_{- \infty}^{\infty} x^2 \rho (x)\,dx ,
\]</span> and the variance is again defined as <span class="math inline">\(E( X^2 ) - (E(X) )^2\)</span>.</p>
<p>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent random variables, then cov(<span class="math inline">\(X,Y)=0\)</span>, and <span class="math display">\[
\mbox{var}( c_1 X + c_2 Y ) = c_1^2 \mbox{var}(X) + c_2^2 \mbox{var}(Y) .
\]</span></p>
</div>
</div>
</div>
<div id="discrete-probability-distributions" class="section level2">
<h2>Discrete Probability Distributions</h2>
<p>There are several probability distributions that arise again and again. We’ll look at a number of these distributions. It is worth knowing what type of distribution you expect under different circumstances, because if you expect a particular distribution you can determine the mean and variance that you expect to observe.</p>
<div id="bernoulli-distribution" class="section level3">
<h3>Bernoulli Distribution</h3>
<p><span class="math inline">\(P(X = 1) = p\\ P(X = 0) = 1-p\)</span></p>
<p>PMF: <span class="math inline">\(p^x(1-p)^{1-x}\)</span></p>
<p><span class="math inline">\(\mu = p\)</span> <span class="math inline">\(\sigma^2 = p(1-p)\)</span></p>
</div>
<div id="binomial-distribution" class="section level3">
<h3>Binomial Distribution</h3>
<p>If a single event or trial has two possible outcomes (say Xi can be 0 or 1 with P(Xi=1)=p), the probability of getting k “ones” in n independent trials is given by the binomial distribution. If n=1, the probability of getting a zero in the trial is P(X=0)=1-p. The probability of getting a one in the trial is P(X=1)=p. These are the only possibilities [P(X=0)+P(X=1)=1].</p>
<p>If n=2, the probability of getting two zeros is P(X=0) = (1-p)2 (getting a zero on the first trial and then independently getting a zero on the second trial), the probability of getting a one is P(X=1) = p(1-p) + (1-p)p = 2 p (1-p), and the probability of getting two ones is P(X=2) = p2. These are the only possibilities [P(X=0)+P(X=1)+P(X=2)=1].</p>
<p>For general n, we use the binomial distribution to determine the probability of k “ones” in n trials:</p>
<p><span class="math inline">\(X \sim Bin(n,p)\)</span> <span class="math inline">\(mu = np\)</span> <span class="math inline">\(\sigma^2 = np(1-p)\)</span> <span class="math inline">\(P(k) = P(X = k) = {n \choose k} p^k(1-p)^{n-k}\)</span></p>
<p>“n choose k” is the number of ways that you can arrange k ones and n-k zeros in a row. For instance, if you wrote down, in a row, the results of n coin tosses, the number of different ways that you could write down all the outcomes and have exactly k heads is “n choose k”.</p>
</div>
<div id="geometric-distribution" class="section level3">
<h3>Geometric Distribution</h3>
<p>If a single event or trial has two possible outcomes (say Xi can be 0 or 1 with P(Xi=1)=p), the probability of having to observe k trials before the first “one” appears is given by the geometic distribution. The probability that the first “one” would appear on the first trial is p.</p>
<p>The probability that the first “one” appears on the second trial is (1-p)*p, because the first trial had to have been a zero followed by a one.</p>
<p>By generalizing this procedure, the probability that there will be k-1 failures before the first success is:</p>
<p><span class="math display">\[
X \sim  Geometric(p) \rightarrow p(k) = (1-p)^{k-1}p \\
\mu = \frac{1}{p} \\
\sigma^2 = \frac{1-p}{p^2}
\]</span></p>
<p>This is the geometric distribution.</p>
<p>A geometric distribution has a mean of <span class="math inline">\(1/p\)</span> and a variance of <span class="math inline">\((1-p)/p^2\)</span>.</p>
<p>Example: If the probability of extinction of an endangered population is estimated to be 0.1 every year, what is the expected time until extinction?</p>
<p>Notice though that the variance in this case is nearly 100! This means that the actual year in which the population will go extinct is very hard to predict accurately. We can see this from the distribution:</p>
</div>
<div id="negative-binomial-distribution" class="section level3">
<h3>Negative Binomial Distribution</h3>
<p>This is an extension of the geometric distribution, describing the waiting time until <span class="math inline">\(r\)</span> “ones” have appeared. The probability of the <span class="math inline">\(r\)</span>th “one” appearing on the <span class="math inline">\(k\)</span>th trial is given by the negative binomial distribution:</p>
<p><span class="math display">\[
X \sim NB(r,p) \rightarrow  p(k) = {k-1 \choose r-1}(1-p)^{k-r}p^r \\
X \sim  Geometric(p) = X \sim  NB(1,p) \\
\mu = \frac{r}{p} \\ 
\sigma^2 = \frac{r(1-p)}{p^2} 
\]</span></p>
<p>Example: If a predator must capture 10 prey before it can grow large enough to reproduce, what would the mean age of onset of reproduction be if the probability of capturing a prey on any given day is 0.1?</p>
<p>Notice that again the variance in this case is quite high (~1000) and that the distribution looks quite skewed (=not symmetric). Some predators will reach reproductive age much sooner and some much later than the average:</p>
</div>
<div id="poisson-distribution" class="section level3">
<h3>Poisson Distribution</h3>
<p>The Poisson distribution arises in two important instances. First, it is an approximation to the binomial distribution when n is large and p is small.</p>
<p>Secondly, the Poisson describes the number of events that will occur in a given time period when the events occur randomly and are independent of one another. Similarly, the Poisson distribution describes the number of events in a given area when the presence or absence of a point is independent of occurrences at other points.</p>
<p>The Poisson distribution looks like: <span class="math display">\[
X \sim P(\lambda) \rightarrow p(k) = e^{-\lambda}\frac{\lambda^k}{k!} \\
\mu = \lambda \\
\sigma^2 = \lambda \\
P(np) \approx  Bin(n,p) \\
\]</span></p>
<p>A Poisson distribution has the unique property that its variance equals its mean, . When the Poisson is used as an approximation to the binomial, the mean and the variance both equal np.</p>
<p>Example: If there are 3 109 basepairs in the human genome and the mutation rate per generation per basepair is 10-9, what is the mean number of new mutations that a child will have, what is the variance in this number, and what will the distribution look like?</p>
<p>Example: If hummingbirds arrive at a flower at a rate per hour, how many visits are expected in x hours of observation and what is the variance in this expectation? If significantly more variance is observed than expected, what might this tell you about hummingbird visits?</p>
<p>Example: (From Romano) If bacteria are spread across a plate at an average density of 5000 per square inch, what is the chance of seeing no bacteria in the viewing field of a microscope if this viewing field is 10-4 square inches? What, therefore, is the probability of seeing at least one cell?</p>
</div>
<div id="hypergeometric-distribution" class="section level3">
<h3>Hypergeometric Distribution</h3>
<p>TBD</p>
</div>
</div>
<div id="continuous-probability-distributions" class="section level2">
<h2>Continuous Probability Distributions</h2>
<p><span class="math display">\[
F(X) = CDF, f(x) = pdf \\
\]</span></p>
<p>For a pdf to be valid, <span class="math display">\[
\int_{-\infty}^{\infty} f(x)dx = 1 \\
F(a) = P(X \leq a) = \int_{-\infty}^a f(x)dx \\
P(a \leq X \leq b) = F(b) - F(a) = P(a &lt; X &lt; b) \\
f(x) = \frac{d}{dx} F(x) \\
\]</span></p>
<p>Expected Values <span class="math display">\[
E[g(x)] = \sum g(x)f(x) = \int_{-\infty}^{\infty} g(x)f(x)dx \\
E[X + Y] = E[X] + E[Y] \\
E[aX + b] = aE[X] + b \\
Var(aX + b) = a^2Var(X) \\
\]</span></p>
<div id="uniform-distribution" class="section level3">
<h3>Uniform Distribution</h3>
<p>Example: Uniform Distribution in <span class="math inline">\([0,1]\)</span>.</p>
<p><span class="math display">\[
F(x) = \left\{ \begin{array}{cl}
                 0 &amp; \mbox{if } x &lt; 0 \\
                 x &amp; \mbox{if } 0 \leq x \leq 1 \\
                 1 &amp; \mbox{if } x &gt; 1 \end{array} \right. ,~~~
\rho (x) = \left\{ \begin{array}{cl}
                 0 &amp; \mbox{if } x &lt; 0 \\
                 1 &amp; \mbox{if } 0 \leq x \leq 1 \\
                 0 &amp; \mbox{if } x &gt; 1 \end{array} \right.
\]</span></p>
<p><span class="math display">\[
E(X) = \int_{- \infty}^{\infty} x \rho (x)\,dx = \int_{0}^{1} x\,dx = 
\frac{1}{2} 
\]</span> <span class="math display">\[
\mbox{var}(X) = \int_{0}^{1} x^2\,dx - \left( \frac{1}{2} \right)^2 =
\frac{1}{3} - \frac{1}{4} = \frac{1}{12} 
\]</span></p>
<p><span class="math display">\[
f(x) = c \hspace{5mm} \alpha \leq x \leq \beta \\
f(x) = 0 \hspace{5mm} otherwise \\
c = \frac{1}{\beta - \alpha} \\
\]</span></p>
<p>NORMAL APPROX. TO BINOMIAL <span class="math display">\[
P(X = i) \approx P(i - 0.5 &lt; Y &lt; i + 0.5) \\\\
\]</span></p>
</div>
<div id="exponential-distribution" class="section level3">
<h3>Exponential Distribution</h3>
<p><span class="math display">\[
X \sim  Exp(\lambda) \rightarrow f(x) = \lambda e^{-\lambda x},\ x \geq 0 \\
\]</span> <span class="math display">\[
F(X) = 1 - e^{-\lambda x} \\
\mu = \frac{1}{\lambda} \\
\sigma^2 = \frac{1}{\lambda^2} \\
\]</span> Distribution is memoryless</p>
<p><span class="math display">\[
E(max(\lambda)) = \frac{3}{2\lambda}\\
\]</span> <span class="math display">\[
Min-  Exp(\lambda_1 + \lambda_2)
\]</span></p>
</div>
<div id="gamma-distribution" class="section level3">
<h3>Gamma Distribution</h3>
<p><span class="math display">\[
X \sim G(\alpha, \lambda) \rightarrow \frac{\lambda^{\alpha}}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x},\ x \geq 0\\
Exp(\lambda) = G(1,\lambda) \\
\mu = \frac{\alpha}{\lambda} \\
\sigma^2 = \frac{\alpha}{\lambda^2} \\
\]</span></p>
</div>
<div id="normal-gaussian-distribution" class="section level3">
<h3>Normal (Gaussian) Distribution</h3>
<p>Paramters: Mean <span class="math inline">\(\mu\)</span>, Variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p><span class="math display">\[
\rho (x) = \frac{1}{\sigma \sqrt{2 \pi}}~\exp \left( - \frac{(x - \mu )^2}
{2 \sigma^2} \right) ,
\]</span></p>
<p><span class="math display">\[
F(x) = \frac{1}{\sigma \sqrt{2 \pi}}~\int_{- \infty}^{x} \exp \left( -
\frac{(t - \mu )^2}{2 \sigma^2} \right) \,dt
\]</span></p>
</div>
</div>
<div id="appendix" class="section level2">
<h2>Appendix</h2>
<p>The Central Limit Theorem</p>
<p>Let <span class="math inline">\(X_1 , \ldots , X_N\)</span> be independent identically distributed (iid) random variables, with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>.<br />
Consider the average value, <span class="math inline">\(A_N = \frac{1}{N} \sum_{i=1}^{N} X_i\)</span>. According to the <strong>Law of Large Numbers</strong>, this average approaches the mean <span class="math inline">\(\mu\)</span> as <span class="math inline">\(N \rightarrow \infty\)</span>, with probability <span class="math inline">\(1\)</span>.</p>
<p>Example: If you toss a fair coin many, many times, the fraction of heads will approach <span class="math inline">\(\frac{1}{2}\)</span>.</p>
<p>The <strong>Central Limit Theorem</strong> states that, for <span class="math inline">\(N\)</span> sufficiently large, values of the random variable <span class="math inline">\(A_N\)</span> are <em>normally distributed</em> about <span class="math inline">\(\mu\)</span>, with variance <span class="math inline">\(\sigma^2 / N\)</span>. The expression for the variance follows from the rules we derived for variance of sums and products: <span class="math display">\[
\mbox{var}( A_N ) = \frac{1}{N^2} \sum_{i=1}^{N} \mbox{var} ( X_i ) =
\frac{\sigma^2}{N} .
\]</span></p>
<p>This means that an observed value for <span class="math inline">\(A_N\)</span> is within one standard deviation (<span class="math inline">\(\sigma / \sqrt{N}\)</span>) of <span class="math inline">\(\mu\)</span> about <span class="math inline">\(68.3\)</span>% of the time, within two standard deviations about <span class="math inline">\(95.4\)</span>% of the time, and within three standard deviations about <span class="math inline">\(99.7\)</span>% of the time. If we wish to compute the expected value of a random variable by taking the average of many different samples, this gives us an idea of how much confidence we can place in our computed approximation. However, it applies only asymptotically as <span class="math inline">\(N \rightarrow \infty\)</span>.</p>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
